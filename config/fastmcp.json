{
  "models": {
    "ba": "claude-3.5-sonnet",
    "developer": "gpt-5", 
    "default": "gpt-5-mini"
  },
  "llm": {
    "base_url": "https://api.openai.com/v1",
    "api_key": "env:OPENAI_API_KEY",
    "litellm_proxy": {
      "enabled": false,
      "url": "http://localhost:4000"
    }
  },
  "github": {
    "token": "env:GITHUB_TOKEN",
    "default_org": "env:GITHUB_ORG"
  },
  "logging": {
    "level": "info",
    "file_logging": true,
    "console_logging": true
  },
  "cost_controls": {
    "max_tokens_per_session": 10000,
    "max_cost_per_session": 5.00,
    "alert_thresholds": {
      "tokens": 8000,
      "cost": 4.00
    }
  },
  "retry_settings": {
    "max_retries": 3,
    "retry_delay_ms": 1000,
    "exponential_backoff": true
  },
  "mcp_servers": {
    "github": {
      "type": "docker",
      "image": "ghcr.io/github/github-mcp-server:latest",
      "timeout_ms": 30000,
      "enabled": true
    },
    "fastmcp": {
      "type": "fastmcp",
      "path": "servers/fastmcp-litellm-server-fixed.js",
      "timeout_ms": 60000,
      "enabled": true,
      "sessionId": "devshop_main",
      "userId": "devshop_user",
      "features": {
        "session_management": true,
        "oauth": false,
        "streaming": false
      }
    },
    "litellm": {
      "type": "local",
      "path": "servers/litellm-server.js",
      "timeout_ms": 60000,
      "enabled": false,
      "note": "Legacy MCP SDK implementation - disabled in favor of FastMCP"
    }
  },
  "directories": {
    "logs": "logs",
    "state": "logs",
    "prompts": "prompts"
  },
  "fastmcp": {
    "version": "1.1.0",
    "migration_status": "active",
    "features_enabled": {
      "enhanced_error_handling": true,
      "session_tracking": true,
      "usage_analytics": true,
      "model_validation": true,
      "cost_estimation": true
    }
  }
}