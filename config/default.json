{
  "models": {
    "ba": "claude-3.5-sonnet",
    "developer": "gpt-5", 
    "default": "gpt-5-mini"
  },
  "llm": {
    "base_url": "https://api.openai.com/v1",
    "api_key": "env:OPENAI_API_KEY",
    "litellm_proxy": {
      "enabled": false,
      "url": "http://localhost:4000"
    }
  },
  "github": {
    "token": "env:GITHUB_TOKEN",
    "default_org": "env:GITHUB_ORG"
  },
  "logging": {
    "level": "info",
    "file_logging": true,
    "console_logging": true
  },
  "cost_controls": {
    "max_tokens_per_session": 10000,
    "max_cost_per_session": 5.00,
    "alert_thresholds": {
      "tokens": 8000,
      "cost": 4.00
    }
  },
  "retry_settings": {
    "max_retries": 3,
    "retry_delay_ms": 1000,
    "exponential_backoff": true
  },
  "mcp_servers": {
    "github": {
      "type": "docker",
      "image": "ghcr.io/github/github-mcp-server:latest",
      "timeout_ms": 30000,
      "enabled": true
    },
    "fastmcp": {
      "type": "fastmcp",
      "path": "servers/fastmcp-litellm-server-fixed.js",
      "timeout_ms": 60000,
      "enabled": true,
      "containerized": true,
      "containerName": "devshop-fastmcp-server",
      "security": {
        "isolation": true,
        "read_only_root": true,
        "non_root_user": true,
        "dropped_capabilities": true,
        "docker_secrets": true
      },
      "features": {
        "session_management": true,
        "type_safety": true,
        "enhanced_error_handling": true
      }
    }
  },
  "directories": {
    "logs": "logs",
    "state": "logs",
    "prompts": "prompts"
  }
}